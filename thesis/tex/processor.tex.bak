\chapter{Basic Processor Architecture and PPU specifications}
\label{chapter:processor}

Next to all processors used these days are built upon the so called von-Neumann architecture \todo{add reference}.
\todo{cite freidmann dissertation}Though the main goal of this group is to provide an alternative analogue architecture that is inspired by nature, there are advantages to the classic model of processors which are needed at some point.
The main advantage of digital systems over analogue systems such as the human brain, is the ability to do calculations at much higher speeds.
For this reason ``normal" processors are responsible for handling experiment data as well as setting up different parts of the experiment.
One such task is applying learning rules to the synapses during or in between experiments which can either be done by hand or with the help of the aforementioned PPU.
The second option is especially valuable when updating synaptic weights during an experiment as the PPU does this much faster than a system which interacts from the outside.
This is important for achieving experimental speeds that are $10^{4}$ times faster than their biological counterparts.

Therefore the PPU is one of many von-Neumann processors in this world and follows the same basic concepts.
It is important to understand these concepts as they build the foundation to this report!

\section{Plasticity Processing Unit}
The PPU was designed by Simon Friedmann \todo{PPU paper} and is a custom processor, that is based on the Power Instruction Set Architecture (PowerISA), which was developed by IBM since 1990.
Specifically the PPU uses POWER7 which is a successor of the original POWER architecture and was released in 2010.
POWER is one of the major CPU architectures that are used nowadays and as such falls under the group of von-Neumann architectures.


\section{Pipelining}

\section{Memory}
Normally the memory of a von-Neumann machine contains both, the program and data.
Therefore it is important, especially for larger scale systems, to keep track of memory usage.
This is e.g. to prevent malicious programs from accessing memory which is used by other software.
For this reason next to all CPUs include a memory management unit (MMU).
It handles all memory access of the processor as it can provide a set of virtual memory addresses which itself then transforms into physical addresses.
Most modern MMUs also incorporate a cache that stores memory operations while others are handled and detects dependencies within this cache which it can resolve.
This results in faster transfer of data as two or more instructions access the same memory which then is handled in the cache.
The PPU though includes only a very simple MMU that does not cache memory instructions and also has matching virtual and physical addresses.
The memory of the Hicann-DLS is 16 kiB in total (ranging from addresses |0x0000| to |0x4000|) and both the vector extension and the main processor use the same MMU.

use this:

This may result in unintended reordering of memory operations which then leads to errors.
Because of this there is the possibility to prohibit such reordering by introducing a memory barrier.
A memory barrier basically is a line of code that that splits the remaining code into code that occurs before the barrier and code that occurs after the barrier.
It prohibits the compiler from mixing instructions from different sides to the barrier due to reordering.
Typically such a memory barrier is called like |asm (:::memory)|, which the compiler recognizes as a memory barrier.
On a processor level there exists also a memory barrier that would typically not be called by a user.
It's called syncing and on PowerPC the instruction |sync| is used for this.
Because the processor itself delays certain instructions to optimize performance (as part of its out-of-order architecture) it may happen that a dependency between two instructions is not detected.
This would result in the very same problem as described earlier.
Therefore the processor can be instructed to wait until all store and load instructions are executed.
The memory controller then sends a signal to the processor that it is all done.
It is fairly obvious that only the second kind of memory barrier helps us in or cause to avoid wrong ordering in the memory controller.Luckily both the VE and the basic processor use the same memory controller which makes |sync| apply in both cases.
Also since all vector instructions must go though the main processor first, any hold executing instructions on the MP affects the VE the same way.
Besides the VE and the MP, the memory also provides access to the FPGA through a different interface \todo{check this} in order to allow for external access to the memory.
This is needed for writing programs into the memory as well as getting results during or after execution.
This also allows for communication during runtime of the PPU.

MMU

\section{Vector Extensions}

Using the same principles as mentioned in the section about von-Neumann architectures, theses is also the possibility to create registers or whole architectures that make use of even more than the common 64-bit.
This is mostly wanted for highly parallel processes such as graphic rendering or audio and video processing \todo{reference}.
But also early supercomputers such as the Cray-1 \todo{reference} made use of vector processing to gain performance by operating on multiple values  simultaneously through a single register.
This could either be realized through a parallel architecture or more easily through pipelining the instruction on one vector over its elements.
The latter one makes sense since there are typically no dependencies between single elements in the same vector.
Nowadays many of the common architectures support vector processing.
A few examples of these are:
\begin{itemize}
    \item x86 with SSE-series and AVX
    \item IA-32 with MMX
    \item AMD K6-2 with 3DNow!
    \item PowerPC with AltiVec and SPE
\end{itemize}
As mentioned these were mostly intended for speeding up tasks like adjusting the contrast of an image.
There is also the possibility to vectorize loops in programming if there are no dependencies between loop cycles.
    

\subsection{AltiVec Vector Extension}
In our case we take a special interest in the AltiVec vector extension which developed by Apple, IBM and Motorola in the mid 1990's and is also known as Vector Media Extension (VMX) and Velocity Engine. 
The AltiVec extension provides the processor with a single-precision floating point and integer SIMD instruction set.
The vector registers are 128-bit each and 32 in total. \todo{http://www.nxp.com/assets/documents/data/en/reference-manuals/ALTIVECPEM.pdf}
These can either hold sixteen 8-bit |char|s, eight 16-bit |short|s or four 32-bit |int|s or single precision |float|s, each signed and unsigned.
Single elements of these vectors can only be accessed through memory because there is no instruction that combines scalar register with vector registers.
Except for one type of instruction that ``splats'' the value of a scalar register into all elements of the vector register.
The reason we take such an interest in this vector extension is that it resembles most characteristics of the PPU's vector extensiond is already implemented in the PowerPC back-end of GCC.
There a few differences though:
\begin{addmargin}[2em]{0em}
    First the PPU's VE uses a conditonal register (CR) to perform instructions only on those elements of a register, that meet the condition, which is specified by the user, while the AltiVec VE utilizes the CR which included in the PowerPC architecture.
    This results in not allowing selective operations on individual elements through the CR but allows for checking if all elements meet the condition in a single instruction.
    If element-wise selection is needed AltiVec offers this through vector masks.
    
    The AltiVec VE has two register on its own though, which are the VCSR and VRSAVE registers.
            The Vector Status and Control Register (VSCR) is responsible for detecting saturation in vector operations and decides which floating point mode is used.
            The Vector Save/Restore Register (VRSAVE) assists applications and operation systems by indicating for each VR if it is currently used by a process and thus must be restored in case of an interrupt.
    
    Both of these register are not available in the PPU's VE but would likely not be needed for simple arithmetic tasks as the PPU is meant to perform.
\end{addmargin}
    
    
\subsection{s2pp Vector Extension}
Vector condition register
Vector accumulator


use this:

The PPU's distinct feature is its vector unit or vector extension (VE) that allows for Single Input Multiple Data (SIMD) operations.
It is literally an extension to the main processors (MP) architecture, since there are very few ways these both can interact.
most importantly all vector instructions that are intended for the VE must pass the MP first.
The MP goes through the hole program step by step and passes any vector instruction to the VE whenever it occurs.
These instructions then go into the so called vector pipeline that holds all vector instructions.
The VE itself then executes all instructions in this pipeline as they occur but and allows for parallel in-order-execution.

The VE was added due to the need for fast handling and writing of the synaptic weights into the array of synaptic values on the HICANN.
Hence the vector unit was equipped with an extra bus that connects to the mentioned synapse array.
The basic processor does not have access to this bus and therefore must use to VE in order to communicate with the synapse array.


\add{vector register file




ALU
FPU
memory
memory controller = MMU
clockcycle
pipeline
}
