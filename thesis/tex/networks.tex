\chapter{Neural Networks and Implementation in Hicann-DLS}
\label{chapter:networks}

This thesis mainly focuses on an essential part of the HICANN-DLS system.
HICANN-DLS stands for \todo{what does hicann stand for?} Digital Learning System.
For this reason it is important to understand the basics behind this and what the PPU is meant to do.

\section{Basics of Neural Networks}
Neural networks build the main application of the Hicann DLS system. This short chapter is meant to give an overview over neural networks and synaptic weights.

On a very abstract level neurons in the brain resemble nodes of a network.
As in a network neurons are interconnected through dendrites, synapses and axons which can be of different strength. 
Also we assume that a neuron is either spiking, meaning it is activated and sends this information to connected neurons or resting meaning it is not activated.
In case a neuron is spiking, it send this information through its axon to other other neurons that are connected to the axon by synapses.
These synapses can work quite differently but have in common that there is a certain weight associated to them, which we will call synaptic weight.
This is equal to a gain with which the signal is either amplified or damped \todo{ is this word right?}.
The signal is then passed through the dendrite of the post-synaptic neuron to the soma where all incoming signals are integrated.
If the integrated signals reach a certain threshold the neuron spikes and then sends a signal itself to other neurons.

With all these physiological parts there are only two important parts we need to take a look at in order to copy the function of a neural network: the neuron and the synapses.
Basically we assume that all neurons are connected to each other through some synaptic weight.
If two neurons are actually not meant to be connected, the synaptic weight simply is set to zero for these neurons to be disconnected.
Now if we display the all neurons inputs and outputs in a 2D plain we get an array of synapses, which is equivalent to a weight matrix.

\section{Implementation in Hicann-DLS}
The Hicann-DLS system tries to implement this structure as close to reality as possible in order to simulate physiological processes in such networks.
At its core it therefore has a so called ``synaptic array" that connects 32 neurons which are located on a single ship to 64 different inputs.
Each neuron's input is aligned along one axis of an array while the 64 outputs of different neurons are on a rectangular axis.
This gives a 2D array of 2048 synapses in total.
The FPGA connects the 64 outputs of the synapse array to neurons in the system while it can also connect the neurons on the same chip to the output channels.
Along each output channel the signal reaches all synapses where it is proccsed.
Each synapse then multiplies the signal it receives with its own weight and sends the result to the inputline of a neuron.
All signals sent by synapses to an input are integrated along the line to a resulting input signal which finally reaches a neuron.
This is not done continuously but discretely and the output signals of all neurons are sent out at the same time.
The output signal of each neuron is also sent to an analogue digital converter (ADC) in order to analyze the data in digital form.
Inside the neurons the individual input signal is evaluated in regard to a threshold and other parameters which decide whether the neuron is spiking or not.
If the neuron is spiking it sends out an output signal to the FPGA which is responsible for spike routing.

The Hicann-DLS system is also equipped with a processing unit that includes a vector extension and some memory for it to operate on.
This is the plasticity processing unit (PPU) which is also connected to the synapse array and thus can read and write synaptic weights.

The whole chip itself is also connected to a field programmable gate array (FPGA) that is able to read and write to the synaptic values as well as the memory of the PPU.
In general the PPU is meant to simulate plasticity of the synapses during experiments while the FPGA should be used to initially set up an experiment and record data.
Therefore the PPU can also read out spiking rates and other additional information of neurons as they are needed for plasticity.
This is realized through the same omnibus that connects the PPU to the memory and virtually the spiking times are accessible through a pointer with a special address.

The synapses in the synapse array are realized as small repetitive circuits that contain 8 bits of information each.
The first two of these bits are used for calibration while the other 6 

\subsection{The plasticy processing unit}

\add{
CURRENT STATE OF PROGRAMMING ON HICANN -> MOTIVATION
main feature analogue spiking
PPU can read spiking times
size and alignment of weights 
read paper first
64 outputs
32 inputs to 32 neurons

}
